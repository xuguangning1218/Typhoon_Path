{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 cell_param,\n",
    "                 return_state,\n",
    "                 return_sequence,\n",
    "                 ):\n",
    "        super(ConvRNN, self).__init__()\n",
    "        self.cell_param = cell_param\n",
    "        self.return_state =return_state\n",
    "        self.return_sequence = return_sequence\n",
    "\n",
    "    def init_paramter(self,shape):\n",
    "        return Variable(torch.zeros(shape).cuda())\n",
    "\n",
    "    def forward(self, input, state=None):\n",
    "\n",
    "        if state is None:\n",
    "            state = self.init_hidden(input)\n",
    "        else:\n",
    "            state = state\n",
    "        # batch_size\n",
    "        self.minibatch_size = input.size()[0]\n",
    "        # time_step\n",
    "        self.n_step = input.size()[1]\n",
    "        # outputs = Variable(torch.zeros(self.minibatch_size, self.n_step, self.cell_param['output_channels'], input.size()[-2], input.size()[-1]).cuda())\n",
    "        outputs = []\n",
    "        # 按时间步处理\n",
    "        for i in range(self.n_step):\n",
    "            x_t = input[:, i, :, :, :]\n",
    "            state = self.cell(x_t, state)\n",
    "            if type(state) == type((1,2)): \n",
    "                outputs.append(state[0]) \n",
    "            else:\n",
    "                outputs.append(state)\n",
    "        outputs = torch.stack(outputs,dim=1)\n",
    "        self.outputs = outputs\n",
    "        if self.return_sequence:\n",
    "            if self.return_state:\n",
    "                return outputs, state\n",
    "            else:\n",
    "                return outputs\n",
    "        else:\n",
    "            if self.return_state:\n",
    "                return state\n",
    "            else:\n",
    "                if type(state) == type((1)): # int\n",
    "                    return state[0]\n",
    "                else:\n",
    "                    return state\n",
    "\n",
    "\n",
    "class ConvRNNCell(nn.Module):\n",
    "    def __init__(self, cell_param):\n",
    "        super(ConvRNNCell, self).__init__()\n",
    "        self.input_dim = cell_param['input_channels']\n",
    "        self.output_dim = cell_param['output_channels']\n",
    "        self.input_to_state_kernel_size = cell_param['input_to_state_kernel_size']\n",
    "        self.state_to_state_kernel_size = cell_param['state_to_state_kernel_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiConvGRU(ConvRNN):\n",
    "    def __init__(self,\n",
    "                 cell_param,\n",
    "                 return_state,\n",
    "                 return_sequence):\n",
    "        super(MultiConvGRU, self).__init__(\n",
    "            cell_param,\n",
    "            return_state,\n",
    "            return_sequence\n",
    "        )\n",
    "\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        self.cell = MConvGRUCell(self.cell_param)\n",
    "\n",
    "    def init_hidden(self, input):\n",
    "\n",
    "        hidden_size = (input.size()[0], self.cell_param['output_channels'], input.size()[-2], input.size()[-1])\n",
    "        h = Variable(self.init_paramter(hidden_size))\n",
    "        state = h\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "\n",
    "class MConvGRUCell(ConvRNNCell):\n",
    "    def __init__(self, cell_param):\n",
    "        super(MConvGRUCell, self).__init__(cell_param)\n",
    "        self.build_model()\n",
    "\n",
    "    def get_parameter(self,shape,init_method = 'xavier'):\n",
    "        param = Parameter(torch.Tensor(*shape).cuda())\n",
    "        if init_method == 'xavier':\n",
    "            nn.init.xavier_uniform_(param)\n",
    "        elif init_method == 'zero':\n",
    "            nn.init.constant_(param,0)\n",
    "        else:\n",
    "            raise ('init method error')\n",
    "        return param\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        input_to_state_shape = [\n",
    "            self.output_dim,\n",
    "            self.input_dim,\n",
    "            self.input_to_state_kernel_size[0],\n",
    "            self.input_to_state_kernel_size[1]\n",
    "        ]\n",
    "        state_to_state_shape = [\n",
    "            self.output_dim,\n",
    "            self.output_dim,\n",
    "            self.state_to_state_kernel_size[0],\n",
    "            self.state_to_state_kernel_size[1]\n",
    "        ]\n",
    "        state_bias_shape = [\n",
    "            1, self.output_dim, 1, 1\n",
    "        ]\n",
    "\n",
    "        self.w_xz1 = self.get_parameter(input_to_state_shape)\n",
    "        self.w_xz2 = self.get_parameter(state_to_state_shape)\n",
    "        self.w_xz3 = self.get_parameter(state_to_state_shape)\n",
    "        self.w_hz = self.get_parameter(state_to_state_shape)\n",
    "\n",
    "        self.w_xr1 = self.get_parameter(input_to_state_shape)\n",
    "        self.w_xr2 = self.get_parameter(state_to_state_shape)\n",
    "        self.w_xr3 = self.get_parameter(state_to_state_shape)\n",
    "        self.w_hr = self.get_parameter(state_to_state_shape)\n",
    "\n",
    "        self.w_xh1 = self.get_parameter(input_to_state_shape)\n",
    "        self.w_xh2 = self.get_parameter(state_to_state_shape)\n",
    "        self.w_xh3 = self.get_parameter(state_to_state_shape)\n",
    "        self.w_hh = self.get_parameter(state_to_state_shape)\n",
    "\n",
    "\n",
    "\n",
    "        self.b_z = self.get_parameter(state_bias_shape,'zero')\n",
    "        self.b_r = self.get_parameter(state_bias_shape,'zero')\n",
    "        self.b_h_ = self.get_parameter(state_bias_shape,'zero')\n",
    "\n",
    "    def same_padding(self,kernel_size):\n",
    "        if kernel_size[0]%2==0 or kernel_size[1]%2==0:\n",
    "            raise('The kernel size must to be odd if you want padding!')\n",
    "        else:\n",
    "            padding = tuple((int((kernel_size[0]-1)/2),int((kernel_size[1]-1)/2)))\n",
    "        return padding\n",
    "\n",
    "\n",
    "    def cell(self, x_t, hidden):\n",
    "        h_tm1 = hidden\n",
    "        Z = torch.sigmoid(\n",
    "            F.conv2d(h_tm1, self.w_hz, bias=None, padding=self.same_padding(self.state_to_state_kernel_size))\n",
    "            + F.conv2d(\n",
    "                F.conv2d(\n",
    "                    F.conv2d(\n",
    "                        x_t,\n",
    "                        self.w_xz1,\n",
    "                        bias=None,\n",
    "                        padding=self.same_padding(self.input_to_state_kernel_size)\n",
    "                    ),\n",
    "                    self.w_xz2,\n",
    "                    bias = None,\n",
    "                    padding = self.same_padding(self.state_to_state_kernel_size)\n",
    "                ),\n",
    "                self.w_xz3,\n",
    "                bias = None,\n",
    "                padding = self.same_padding(self.state_to_state_kernel_size)\n",
    "            )\n",
    "            + self.b_z\n",
    "        )\n",
    "\n",
    "        R = torch.sigmoid(\n",
    "            F.conv2d(h_tm1, self.w_hr, bias=None, padding=self.same_padding(self.state_to_state_kernel_size))\n",
    "            + F.conv2d(\n",
    "                F.conv2d(\n",
    "                    F.conv2d(\n",
    "                        x_t,\n",
    "                        self.w_xr1,\n",
    "                        bias=None,\n",
    "                        padding=self.same_padding(self.input_to_state_kernel_size)\n",
    "                    ),\n",
    "                    self.w_xr2,\n",
    "                    bias = None,\n",
    "                    padding = self.same_padding(self.state_to_state_kernel_size)\n",
    "                ),\n",
    "                self.w_xr3,\n",
    "                bias = None,\n",
    "                padding = self.same_padding(self.state_to_state_kernel_size)\n",
    "            )\n",
    "            + self.b_r\n",
    "        )\n",
    "\n",
    "        H_ = F.leaky_relu(\n",
    "            F.conv2d(h_tm1,self.w_hh,bias = None,padding = self.same_padding(self.state_to_state_kernel_size))\n",
    "            + R*F.conv2d(\n",
    "                    F.conv2d(\n",
    "                        F.conv2d(\n",
    "                            x_t,\n",
    "                            self.w_xh1,\n",
    "                            bias=None,\n",
    "                            padding = self.same_padding(self.input_to_state_kernel_size)\n",
    "                        ),\n",
    "                        self.w_xh2,\n",
    "                        bias = None,\n",
    "                        padding = self.same_padding(self.state_to_state_kernel_size)\n",
    "                    ),\n",
    "                    self.w_xh3,\n",
    "                    bias = None,\n",
    "                    padding = self.same_padding(self.state_to_state_kernel_size)\n",
    "                )\n",
    "            + self.b_h_,negative_slope = 0.2\n",
    "        )\n",
    "\n",
    "        H = (1-Z)*H_ + Z*h_tm1\n",
    "\n",
    "        return H\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        h_t = self.cell(input,hidden)\n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Channel Attention (CA) Layer\n",
    "class CALayer(nn.Sequential):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(CALayer, self).__init__()\n",
    "        self.conv_du = nn.Sequential(\n",
    "                # global average pooling: feature --> point\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                # feature channel downscale and upscale --> channel weight\n",
    "                nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=True),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv_du(x)\n",
    "        return x * y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Reanalysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "# from torchsummary import summary\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# forecast 24-hour lead time \n",
    "pre_seq = 4\n",
    "batch_size = 128\n",
    "epochs = 128\n",
    "min_val_loss = 100\n",
    "model_name = './model_saver/Model.pkl'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/CMA_train_'+str(pre_seq*6)+'h.csv', header=None)\n",
    "test= pd.read_csv('./data/CMA_test_'+str(pre_seq*6)+'h.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8406, 59), (2747, 59))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIPER_feature =  pd.concat((train, test), axis=0)\n",
    "CLIPER_feature.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wide_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "X_wide = X_wide_scaler.fit_transform(CLIPER_feature.iloc[:, 6:])\n",
    "X_wide_train = X_wide[0: train.shape[0], :]\n",
    "\n",
    "y = y_scaler.fit_transform(CLIPER_feature.loc[:, 3:4])\n",
    "y_train = y[0: train.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reanalysis_type = 'z'\n",
    "# 0 means now \n",
    "# 1 means 6-hour ago\n",
    "# 2 means 12-hour ago\n",
    "ahead_times = [0,1,2,3]\n",
    "pressures = [1000, 750, 500, 250]\n",
    "sequential_reanalysis_list = []\n",
    "reanalysis_test_dict = {}\n",
    "X_deep_scaler_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahead_time: 0 (8406, 1, 4, 31, 31)\n",
      "ahead_time: 1 (8406, 1, 4, 31, 31)\n",
      "ahead_time: 2 (8406, 1, 4, 31, 31)\n",
      "ahead_time: 3 (8406, 1, 4, 31, 31)\n"
     ]
    }
   ],
   "source": [
    "for ahead_time in ahead_times:\n",
    "\n",
    "    reanalysis_list = []\n",
    "    for pressure in pressures:\n",
    "        \n",
    "        folder = None\n",
    "        if ahead_time == 0:\n",
    "            folder = reanalysis_type\n",
    "        else:\n",
    "            folder = reanalysis_type + '_' + str(ahead_time*6)\n",
    "        train_reanalysis_csv = pd.read_csv('./data/ERA_Interim/'+folder+'/'+reanalysis_type+str(pressure)+'_train_31_31.csv', header=None)\n",
    "        test_reanalysis_csv = pd.read_csv('./data/ERA_Interim/'+folder+'/'+reanalysis_type+str(pressure)+'_test_31_31.csv', header=None)\n",
    "        \n",
    "        train_reanalysis = train_reanalysis_csv[train_reanalysis_csv[0].isin(train[0].unique())]\n",
    "        test_reanalysis = test_reanalysis_csv[test_reanalysis_csv[0].isin(test[0].unique())]\n",
    "        reanalysis_test_dict[reanalysis_type+str(pressure)+str(ahead_time)] = test_reanalysis\n",
    "        \n",
    "        reanalysis =  pd.concat((train_reanalysis, test_reanalysis), axis=0)\n",
    "        reanalysis.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        scaler_name = reanalysis_type +str(pressure) + str(ahead_time)\n",
    "        X_deep_scaler_dict[scaler_name] = MinMaxScaler()\n",
    "        X_deep = X_deep_scaler_dict[scaler_name] .fit_transform(reanalysis.loc[:, 5:])\n",
    "        \n",
    "        X_deep_final = X_deep[0: train.shape[0], :].reshape(-1, 1, 1, 31, 31)\n",
    "        reanalysis_list.append(X_deep_final)\n",
    "    \n",
    "    X_deep_temp = np.concatenate(reanalysis_list[:], axis=2)\n",
    "    print(\"ahead_time:\", ahead_time, X_deep_temp.shape)\n",
    "    sequential_reanalysis_list.append(X_deep_temp)\n",
    "\n",
    "X_deep_train = np.concatenate(sequential_reanalysis_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8406, 53), (8406, 4, 4, 31, 31))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wide_train.shape, X_deep_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLoader(Data.Dataset):\n",
    "    def __init__(self, X_wide_train, X_deep_train, y_train):\n",
    "        self.X_wide_train = X_wide_train\n",
    "        self.X_deep_train = X_deep_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return [self.X_wide_train[index], self.X_deep_train[index]], self.y_train[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_wide_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_index = [*range(0, len(X_wide_train))]\n",
    "\n",
    "train_index, val_index, _, _, = train_test_split(full_train_index,full_train_index,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7565, 841)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_index), len(val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.DataLoader(\n",
    "    TrainLoader(X_wide_train[train_index], X_deep_train[train_index], y_train[train_index]), \n",
    "                                                 batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = torch.utils.data.DataLoader(\n",
    "    TrainLoader(X_wide_train[val_index], X_deep_train[val_index], y_train[val_index]), \n",
    "                                                 batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide & Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.channel_attention = CALayer(4, reduction=2)\n",
    "        \n",
    "        self.convGRU1 = MultiConvGRU(cell_param={\n",
    "            'input_channels' : 4,\n",
    "            'output_channels' : 64,\n",
    "            'input_to_state_kernel_size' : (3, 3),\n",
    "            'state_to_state_kernel_size' : (3, 3)\n",
    "            }, return_state=False, return_sequence=True)\n",
    "        \n",
    "        self.channel_attention_0 = CALayer(64)\n",
    "        \n",
    "        self.convGRU2 = MultiConvGRU(cell_param={\n",
    "            'input_channels' : 64,\n",
    "            'output_channels' : 128,\n",
    "            'input_to_state_kernel_size' : (3, 3),\n",
    "            'state_to_state_kernel_size' : (3, 3)\n",
    "            }, return_state=False, return_sequence=True)\n",
    "        \n",
    "        self.channel_attention_1 = CALayer(128)\n",
    "        \n",
    "        self.convGRU3 = MultiConvGRU(cell_param={\n",
    "            'input_channels' : 128,\n",
    "            'output_channels' : 256,\n",
    "            'input_to_state_kernel_size' : (3, 3),\n",
    "            'state_to_state_kernel_size' : (3, 3)\n",
    "            }, return_state=False, return_sequence=False)\n",
    "        \n",
    "        self.channel_attention_2 = CALayer(256)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(53 + 128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, wide, deep):\n",
    "        \n",
    "        temp_deep_list = []\n",
    "        for i in range(deep.shape[1]):\n",
    "            temp_deep = deep[:, i, :, :, :]\n",
    "            temp_deep = temp_deep + self.channel_attention(temp_deep)\n",
    "            temp_deep_list.append(temp_deep)\n",
    "\n",
    "        deep = torch.stack(temp_deep_list, dim=1)\n",
    "        \n",
    "        deep = self.convGRU1(deep)\n",
    "        \n",
    "\n",
    "        temp_deep_list = []\n",
    "        for i in range(deep.shape[1]):\n",
    "            temp_deep = deep[:, i, :, :, :]\n",
    "            temp_deep = temp_deep + self.channel_attention_0(temp_deep)\n",
    "            temp_deep = self.pool(temp_deep)\n",
    "            temp_deep_list.append(temp_deep)\n",
    "\n",
    "        deep = torch.stack(temp_deep_list, dim=1)\n",
    "        \n",
    "        deep = self.convGRU2(deep)\n",
    "        \n",
    "        temp_deep_list = []\n",
    "        for i in range(deep.shape[1]):\n",
    "            temp_deep = deep[:, i, :, :, :]\n",
    "            temp_deep = temp_deep + self.channel_attention_1(temp_deep)\n",
    "            temp_deep = self.pool(temp_deep)\n",
    "            temp_deep_list.append(temp_deep)\n",
    "\n",
    "        deep = torch.stack(temp_deep_list, dim=1)\n",
    "        \n",
    "        _h = self.convGRU3(deep)\n",
    "        \n",
    "        _h = _h + self.channel_attention_2(_h)\n",
    "        \n",
    "        deep = self.pool(_h)\n",
    "        \n",
    "        deep = deep.view(-1, 256 * 3 * 3)\n",
    "        \n",
    "        deep = self.fc1(deep)\n",
    "        wide = wide.view(-1, 53)\n",
    "        wide_n_deep = torch.cat((wide, deep),1)\n",
    "        \n",
    "        wide_n_deep = F.relu(self.fc2(wide_n_deep))\n",
    "        wide_n_deep = F.relu(self.fc3(wide_n_deep))\n",
    "        return wide_n_deep\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      " AdaptiveAvgPool2d-1              [-1, 4, 1, 1]               0\n",
      "            Conv2d-2              [-1, 2, 1, 1]              10\n",
      "              ReLU-3              [-1, 2, 1, 1]               0\n",
      "            Conv2d-4              [-1, 4, 1, 1]              12\n",
      "           Sigmoid-5              [-1, 4, 1, 1]               0\n",
      " AdaptiveAvgPool2d-6              [-1, 4, 1, 1]               0\n",
      "            Conv2d-7              [-1, 2, 1, 1]              10\n",
      "              ReLU-8              [-1, 2, 1, 1]               0\n",
      "            Conv2d-9              [-1, 4, 1, 1]              12\n",
      "          Sigmoid-10              [-1, 4, 1, 1]               0\n",
      "AdaptiveAvgPool2d-11              [-1, 4, 1, 1]               0\n",
      "           Conv2d-12              [-1, 2, 1, 1]              10\n",
      "             ReLU-13              [-1, 2, 1, 1]               0\n",
      "           Conv2d-14              [-1, 4, 1, 1]              12\n",
      "          Sigmoid-15              [-1, 4, 1, 1]               0\n",
      "AdaptiveAvgPool2d-16              [-1, 4, 1, 1]               0\n",
      "           Conv2d-17              [-1, 2, 1, 1]              10\n",
      "             ReLU-18              [-1, 2, 1, 1]               0\n",
      "           Conv2d-19              [-1, 4, 1, 1]              12\n",
      "          Sigmoid-20              [-1, 4, 1, 1]               0\n",
      "     MConvGRUCell-21           [-1, 64, 31, 31]               0\n",
      "     MConvGRUCell-22           [-1, 64, 31, 31]               0\n",
      "     MConvGRUCell-23           [-1, 64, 31, 31]               0\n",
      "     MConvGRUCell-24           [-1, 64, 31, 31]               0\n",
      "     MultiConvGRU-25        [-1, 4, 64, 31, 31]               0\n",
      "AdaptiveAvgPool2d-26             [-1, 64, 1, 1]               0\n",
      "           Conv2d-27              [-1, 4, 1, 1]             260\n",
      "             ReLU-28              [-1, 4, 1, 1]               0\n",
      "           Conv2d-29             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-30             [-1, 64, 1, 1]               0\n",
      "        MaxPool2d-31           [-1, 64, 15, 15]               0\n",
      "AdaptiveAvgPool2d-32             [-1, 64, 1, 1]               0\n",
      "           Conv2d-33              [-1, 4, 1, 1]             260\n",
      "             ReLU-34              [-1, 4, 1, 1]               0\n",
      "           Conv2d-35             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-36             [-1, 64, 1, 1]               0\n",
      "        MaxPool2d-37           [-1, 64, 15, 15]               0\n",
      "AdaptiveAvgPool2d-38             [-1, 64, 1, 1]               0\n",
      "           Conv2d-39              [-1, 4, 1, 1]             260\n",
      "             ReLU-40              [-1, 4, 1, 1]               0\n",
      "           Conv2d-41             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-42             [-1, 64, 1, 1]               0\n",
      "        MaxPool2d-43           [-1, 64, 15, 15]               0\n",
      "AdaptiveAvgPool2d-44             [-1, 64, 1, 1]               0\n",
      "           Conv2d-45              [-1, 4, 1, 1]             260\n",
      "             ReLU-46              [-1, 4, 1, 1]               0\n",
      "           Conv2d-47             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-48             [-1, 64, 1, 1]               0\n",
      "        MaxPool2d-49           [-1, 64, 15, 15]               0\n",
      "     MConvGRUCell-50          [-1, 128, 15, 15]               0\n",
      "     MConvGRUCell-51          [-1, 128, 15, 15]               0\n",
      "     MConvGRUCell-52          [-1, 128, 15, 15]               0\n",
      "     MConvGRUCell-53          [-1, 128, 15, 15]               0\n",
      "     MultiConvGRU-54       [-1, 4, 128, 15, 15]               0\n",
      "AdaptiveAvgPool2d-55            [-1, 128, 1, 1]               0\n",
      "           Conv2d-56              [-1, 8, 1, 1]           1,032\n",
      "             ReLU-57              [-1, 8, 1, 1]               0\n",
      "           Conv2d-58            [-1, 128, 1, 1]           1,152\n",
      "          Sigmoid-59            [-1, 128, 1, 1]               0\n",
      "        MaxPool2d-60            [-1, 128, 7, 7]               0\n",
      "AdaptiveAvgPool2d-61            [-1, 128, 1, 1]               0\n",
      "           Conv2d-62              [-1, 8, 1, 1]           1,032\n",
      "             ReLU-63              [-1, 8, 1, 1]               0\n",
      "           Conv2d-64            [-1, 128, 1, 1]           1,152\n",
      "          Sigmoid-65            [-1, 128, 1, 1]               0\n",
      "        MaxPool2d-66            [-1, 128, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 128, 1, 1]               0\n",
      "           Conv2d-68              [-1, 8, 1, 1]           1,032\n",
      "             ReLU-69              [-1, 8, 1, 1]               0\n",
      "           Conv2d-70            [-1, 128, 1, 1]           1,152\n",
      "          Sigmoid-71            [-1, 128, 1, 1]               0\n",
      "        MaxPool2d-72            [-1, 128, 7, 7]               0\n",
      "AdaptiveAvgPool2d-73            [-1, 128, 1, 1]               0\n",
      "           Conv2d-74              [-1, 8, 1, 1]           1,032\n",
      "             ReLU-75              [-1, 8, 1, 1]               0\n",
      "           Conv2d-76            [-1, 128, 1, 1]           1,152\n",
      "          Sigmoid-77            [-1, 128, 1, 1]               0\n",
      "        MaxPool2d-78            [-1, 128, 7, 7]               0\n",
      "     MConvGRUCell-79            [-1, 256, 7, 7]               0\n",
      "     MConvGRUCell-80            [-1, 256, 7, 7]               0\n",
      "     MConvGRUCell-81            [-1, 256, 7, 7]               0\n",
      "     MConvGRUCell-82            [-1, 256, 7, 7]               0\n",
      "     MultiConvGRU-83            [-1, 256, 7, 7]               0\n",
      "AdaptiveAvgPool2d-84            [-1, 256, 1, 1]               0\n",
      "           Conv2d-85             [-1, 16, 1, 1]           4,112\n",
      "             ReLU-86             [-1, 16, 1, 1]               0\n",
      "           Conv2d-87            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-88            [-1, 256, 1, 1]               0\n",
      "        MaxPool2d-89            [-1, 256, 3, 3]               0\n",
      "           Linear-90                  [-1, 128]         295,040\n",
      "           Linear-91                   [-1, 64]          11,648\n",
      "           Linear-92                    [-1, 2]             130\n",
      "================================================================\n",
      "Total params: 326,426\n",
      "Trainable params: 326,426\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.11\n",
      "Forward/backward pass size (MB): 6.67\n",
      "Params size (MB): 1.25\n",
      "Estimated Total Size (MB): 11.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# net = net.to(device)\n",
    "\n",
    "# summary(net, [(1, 1, 1, 53),(4, 4, 31, 31)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs [1/128] cost:25.00s train_loss: 7.85815 val_loss: 0.35427\n",
      "epochs [2/128] cost:26.00s train_loss: 2.14582 val_loss: 0.14928\n",
      "epochs [3/128] cost:25.00s train_loss: 1.19259 val_loss: 0.13098\n",
      "epochs [4/128] cost:26.00s train_loss: 1.00862 val_loss: 0.12909\n",
      "epochs [5/128] cost:25.00s train_loss: 0.99270 val_loss: 0.10852\n",
      "epochs [6/128] cost:26.00s train_loss: 0.91470 val_loss: 0.11569\n",
      "epochs [7/128] cost:26.00s train_loss: 0.91949 val_loss: 0.12824\n",
      "epochs [8/128] cost:26.00s train_loss: 0.89364 val_loss: 0.09920\n",
      "epochs [9/128] cost:26.00s train_loss: 0.80542 val_loss: 0.11395\n",
      "epochs [10/128] cost:26.00s train_loss: 0.83544 val_loss: 0.09532\n",
      "epochs [11/128] cost:26.00s train_loss: 0.79917 val_loss: 0.08974\n",
      "epochs [12/128] cost:26.00s train_loss: 0.78400 val_loss: 0.09207\n",
      "epochs [13/128] cost:26.00s train_loss: 0.74732 val_loss: 0.08111\n",
      "epochs [14/128] cost:26.00s train_loss: 0.76885 val_loss: 0.12907\n",
      "epochs [15/128] cost:26.00s train_loss: 0.81294 val_loss: 0.08455\n",
      "epochs [16/128] cost:26.00s train_loss: 0.73966 val_loss: 0.10566\n",
      "epochs [17/128] cost:26.00s train_loss: 0.72762 val_loss: 0.09438\n",
      "epochs [18/128] cost:26.00s train_loss: 0.74625 val_loss: 0.08589\n",
      "epochs [19/128] cost:27.00s train_loss: 0.70207 val_loss: 0.07926\n",
      "epochs [20/128] cost:26.00s train_loss: 0.69281 val_loss: 0.08917\n",
      "epochs [21/128] cost:26.00s train_loss: 0.70033 val_loss: 0.07858\n",
      "epochs [22/128] cost:27.00s train_loss: 0.66932 val_loss: 0.08350\n",
      "epochs [23/128] cost:26.00s train_loss: 0.64504 val_loss: 0.08134\n",
      "epochs [24/128] cost:27.00s train_loss: 0.68250 val_loss: 0.09698\n",
      "epochs [25/128] cost:26.00s train_loss: 0.65800 val_loss: 0.08007\n",
      "epochs [26/128] cost:26.00s train_loss: 0.65050 val_loss: 0.07793\n",
      "epochs [27/128] cost:26.00s train_loss: 0.68186 val_loss: 0.08384\n",
      "epochs [28/128] cost:26.00s train_loss: 0.64079 val_loss: 0.07864\n",
      "epochs [29/128] cost:26.00s train_loss: 0.67698 val_loss: 0.07991\n",
      "epochs [30/128] cost:26.00s train_loss: 0.65325 val_loss: 0.07713\n",
      "epochs [31/128] cost:26.00s train_loss: 0.65872 val_loss: 0.08613\n",
      "epochs [32/128] cost:26.00s train_loss: 0.63204 val_loss: 0.08861\n",
      "epochs [33/128] cost:26.00s train_loss: 0.63578 val_loss: 0.07122\n",
      "epochs [34/128] cost:26.00s train_loss: 0.59578 val_loss: 0.07655\n",
      "epochs [35/128] cost:25.00s train_loss: 0.62342 val_loss: 0.07913\n",
      "epochs [36/128] cost:27.00s train_loss: 0.59355 val_loss: 0.07757\n",
      "epochs [37/128] cost:27.00s train_loss: 0.59608 val_loss: 0.08816\n",
      "epochs [38/128] cost:26.00s train_loss: 0.63170 val_loss: 0.09212\n",
      "epochs [39/128] cost:27.00s train_loss: 0.64496 val_loss: 0.08908\n",
      "epochs [40/128] cost:26.00s train_loss: 0.60149 val_loss: 0.09190\n",
      "epochs [41/128] cost:26.00s train_loss: 0.61262 val_loss: 0.06902\n",
      "epochs [42/128] cost:26.00s train_loss: 0.56282 val_loss: 0.07801\n",
      "epochs [43/128] cost:26.00s train_loss: 0.59310 val_loss: 0.06484\n",
      "epochs [44/128] cost:26.00s train_loss: 0.55650 val_loss: 0.06397\n",
      "epochs [45/128] cost:26.00s train_loss: 0.54863 val_loss: 0.07391\n",
      "epochs [46/128] cost:26.00s train_loss: 0.59954 val_loss: 0.09504\n",
      "epochs [47/128] cost:26.00s train_loss: 0.62455 val_loss: 0.08313\n",
      "epochs [48/128] cost:26.00s train_loss: 0.58304 val_loss: 0.08709\n",
      "epochs [49/128] cost:26.00s train_loss: 0.56409 val_loss: 0.07126\n",
      "epochs [50/128] cost:26.00s train_loss: 0.54716 val_loss: 0.07628\n",
      "epochs [51/128] cost:26.00s train_loss: 0.58006 val_loss: 0.06518\n",
      "epochs [52/128] cost:26.00s train_loss: 0.54803 val_loss: 0.06481\n",
      "epochs [53/128] cost:27.00s train_loss: 0.56715 val_loss: 0.06833\n",
      "epochs [54/128] cost:26.00s train_loss: 0.54107 val_loss: 0.07778\n",
      "epochs [55/128] cost:25.00s train_loss: 0.53516 val_loss: 0.08417\n",
      "epochs [56/128] cost:26.00s train_loss: 0.56125 val_loss: 0.06285\n",
      "epochs [57/128] cost:26.00s train_loss: 0.52134 val_loss: 0.07655\n",
      "epochs [58/128] cost:26.00s train_loss: 0.56336 val_loss: 0.05969\n",
      "epochs [59/128] cost:26.00s train_loss: 0.52801 val_loss: 0.06795\n",
      "epochs [60/128] cost:26.00s train_loss: 0.51832 val_loss: 0.05861\n",
      "epochs [61/128] cost:26.00s train_loss: 0.51289 val_loss: 0.08125\n",
      "epochs [62/128] cost:26.00s train_loss: 0.52080 val_loss: 0.06341\n",
      "epochs [63/128] cost:26.00s train_loss: 0.52437 val_loss: 0.05504\n",
      "epochs [64/128] cost:27.00s train_loss: 0.51541 val_loss: 0.05456\n",
      "epochs [65/128] cost:26.00s train_loss: 0.54556 val_loss: 0.12065\n",
      "epochs [66/128] cost:26.00s train_loss: 0.94725 val_loss: 0.10145\n",
      "epochs [67/128] cost:26.00s train_loss: 0.83665 val_loss: 0.09239\n",
      "epochs [68/128] cost:26.00s train_loss: 0.85637 val_loss: 0.11198\n",
      "epochs [69/128] cost:26.00s train_loss: 0.85294 val_loss: 0.11888\n",
      "epochs [70/128] cost:26.00s train_loss: 0.86751 val_loss: 0.10298\n",
      "epochs [71/128] cost:26.00s train_loss: 0.85488 val_loss: 0.11161\n",
      "epochs [72/128] cost:26.00s train_loss: 0.84783 val_loss: 0.09704\n",
      "epochs [73/128] cost:26.00s train_loss: 18.30931 val_loss: 1.99059\n",
      "epochs [74/128] cost:25.00s train_loss: 17.03693 val_loss: 1.96365\n",
      "epochs [75/128] cost:26.00s train_loss: 16.94892 val_loss: 2.00034\n",
      "epochs [76/128] cost:25.00s train_loss: 16.99187 val_loss: 1.97014\n",
      "epochs [77/128] cost:26.00s train_loss: 16.97666 val_loss: 2.00837\n",
      "epochs [78/128] cost:25.00s train_loss: 16.95942 val_loss: 2.01360\n",
      "epochs [79/128] cost:25.00s train_loss: 16.99849 val_loss: 1.98518\n",
      "epochs [80/128] cost:25.00s train_loss: 16.97459 val_loss: 1.97551\n",
      "epochs [81/128] cost:25.00s train_loss: 16.95487 val_loss: 2.00984\n",
      "epochs [82/128] cost:25.00s train_loss: 16.94904 val_loss: 2.01478\n",
      "epochs [83/128] cost:25.00s train_loss: 17.01422 val_loss: 1.97264\n",
      "epochs [84/128] cost:25.00s train_loss: 16.98387 val_loss: 1.94611\n",
      "epochs [85/128] cost:25.00s train_loss: 16.93799 val_loss: 1.97356\n",
      "epochs [86/128] cost:25.00s train_loss: 17.03463 val_loss: 1.98010\n",
      "epochs [87/128] cost:25.00s train_loss: 16.96696 val_loss: 1.94351\n",
      "epochs [88/128] cost:25.00s train_loss: 17.03412 val_loss: 1.96356\n",
      "epochs [89/128] cost:25.00s train_loss: 16.97769 val_loss: 1.95879\n",
      "epochs [90/128] cost:25.00s train_loss: 17.03840 val_loss: 1.97032\n",
      "epochs [91/128] cost:25.00s train_loss: 17.02597 val_loss: 1.97506\n",
      "epochs [92/128] cost:25.00s train_loss: 16.95652 val_loss: 2.01208\n",
      "epochs [93/128] cost:25.00s train_loss: 16.96564 val_loss: 1.96901\n",
      "epochs [94/128] cost:25.00s train_loss: 17.04292 val_loss: 1.95449\n",
      "epochs [95/128] cost:25.00s train_loss: 16.99759 val_loss: 1.97845\n",
      "epochs [96/128] cost:25.00s train_loss: 17.00014 val_loss: 2.00617\n",
      "epochs [97/128] cost:25.00s train_loss: 16.95360 val_loss: 1.98435\n",
      "epochs [98/128] cost:25.00s train_loss: 16.96105 val_loss: 1.98960\n",
      "epochs [99/128] cost:26.00s train_loss: 16.97225 val_loss: 1.98305\n",
      "epochs [100/128] cost:25.00s train_loss: 17.01121 val_loss: 1.96278\n",
      "epochs [101/128] cost:25.00s train_loss: 16.99270 val_loss: 1.98217\n",
      "epochs [102/128] cost:25.00s train_loss: 17.00349 val_loss: 1.97357\n",
      "epochs [103/128] cost:25.00s train_loss: 17.00149 val_loss: 1.92463\n",
      "epochs [104/128] cost:26.00s train_loss: 16.99812 val_loss: 1.94175\n",
      "epochs [105/128] cost:26.00s train_loss: 17.00873 val_loss: 1.99056\n",
      "epochs [106/128] cost:26.00s train_loss: 17.00177 val_loss: 1.95915\n",
      "epochs [107/128] cost:26.00s train_loss: 17.00241 val_loss: 1.97806\n",
      "epochs [108/128] cost:25.00s train_loss: 17.00094 val_loss: 1.96093\n",
      "epochs [109/128] cost:26.00s train_loss: 17.07674 val_loss: 1.91311\n",
      "epochs [110/128] cost:26.00s train_loss: 16.97076 val_loss: 2.00317\n",
      "epochs [111/128] cost:26.00s train_loss: 16.99640 val_loss: 1.96044\n",
      "epochs [112/128] cost:26.00s train_loss: 16.98925 val_loss: 1.98584\n",
      "epochs [113/128] cost:26.00s train_loss: 16.96961 val_loss: 1.99840\n",
      "epochs [114/128] cost:25.00s train_loss: 17.01468 val_loss: 1.93145\n",
      "epochs [115/128] cost:26.00s train_loss: 16.97329 val_loss: 1.94931\n",
      "epochs [116/128] cost:26.00s train_loss: 16.96739 val_loss: 2.00290\n",
      "epochs [117/128] cost:25.00s train_loss: 16.99424 val_loss: 1.99009\n",
      "epochs [118/128] cost:25.00s train_loss: 16.98473 val_loss: 1.97236\n",
      "epochs [119/128] cost:25.00s train_loss: 17.02752 val_loss: 1.94471\n",
      "epochs [120/128] cost:25.00s train_loss: 16.96943 val_loss: 1.97053\n",
      "epochs [121/128] cost:27.00s train_loss: 16.99759 val_loss: 1.99159\n",
      "epochs [122/128] cost:26.00s train_loss: 16.97144 val_loss: 1.98552\n",
      "epochs [123/128] cost:25.00s train_loss: 16.99947 val_loss: 1.97137\n",
      "epochs [124/128] cost:25.00s train_loss: 16.92692 val_loss: 2.00642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs [125/128] cost:26.00s train_loss: 16.95633 val_loss: 1.97991\n",
      "epochs [126/128] cost:26.00s train_loss: 16.99985 val_loss: 1.97890\n",
      "epochs [127/128] cost:25.00s train_loss: 16.99366 val_loss: 2.01402\n",
      "epochs [128/128] cost:26.00s train_loss: 16.97661 val_loss: 1.98880\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "full_train_index = [*range(0, len(X_wide_train))]\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    starttime = datetime.datetime.now()\n",
    "    train_index, val_index, _, _, = train_test_split(full_train_index,full_train_index,test_size=0.1)\n",
    "    train_dataset = torch.utils.data.DataLoader(\n",
    "        TrainLoader(X_wide_train[train_index], X_deep_train[train_index], y_train[train_index]), \n",
    "                                                 batch_size=batch_size,)\n",
    "    val_dataset = torch.utils.data.DataLoader(\n",
    "        TrainLoader(X_wide_train[val_index], X_deep_train[val_index], y_train[val_index]), \n",
    "                                                 batch_size=batch_size,)\n",
    "    # training\n",
    "    total_train_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(train_dataset):\n",
    "        if torch.cuda.is_available():\n",
    "            net.cuda()\n",
    "            X_wide_train_cuda = batch_x[0].float().cuda()\n",
    "            X_deep_train_cuda = batch_x[1].float().cuda()\n",
    "            y_train_cuda = batch_y.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        pred_y = net(X_wide_train_cuda, X_deep_train_cuda)\n",
    "        loss = criterion(pred_y, y_train_cuda)\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # validation\n",
    "    total_val_loss = 0\n",
    "    for _,(batch_val_x, batch_val_y) in enumerate(val_dataset):\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            X_wide_val_cuda = batch_val_x[0].float().cuda()\n",
    "            X_deep_val_cuda = batch_val_x[1].float().cuda()\n",
    "            y_val_cuda = batch_val_y.cuda()\n",
    "        \n",
    "        pred_y = net(X_wide_val_cuda, X_deep_val_cuda)\n",
    "        val_loss = criterion(pred_y, y_val_cuda)\n",
    "        total_val_loss += val_loss.item()\n",
    "    \n",
    "        # print statistics\n",
    "    if min_val_loss > total_val_loss:\n",
    "        torch.save(net.state_dict(), model_name)\n",
    "        min_val_loss = total_val_loss\n",
    "    endtime = datetime.datetime.now()\n",
    "    print('epochs [%d/%d] cost:%.2fs train_loss: %.5f val_loss: %.5f' % \n",
    "          (epoch + 1, epochs, (endtime-starttime).seconds, total_train_loss, total_val_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net.load_state_dict(torch.load(model_name))\n",
    "years = test[5].unique()\n",
    "test_list = []\n",
    "\n",
    "for year in years:\n",
    "    temp = test[test[5]==year]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    test_list.append(temp)\n",
    "    \n",
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 年:\n",
      "avg lat: 0.668006118436217\n",
      "avg long: 0.8646890850319199\n",
      "avg distance error: 125.21606908851712\n",
      "2016 年:\n",
      "avg lat: 0.8636830070511208\n",
      "avg long: 0.9129902970327669\n",
      "avg distance error: 145.4701460031522\n",
      "2017 年:\n",
      "avg lat: 0.7577311471981166\n",
      "avg long: 0.9723578004276063\n",
      "avg distance error: 141.04057444296916\n",
      "2018 年:\n",
      "avg lat: 0.8711327388327995\n",
      "avg long: 1.0219548776782772\n",
      "avg distance error: 152.9109631050797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for year, _test in zip(years, test_list):\n",
    "\n",
    "        print(year, '年:')\n",
    "\n",
    "        y_test_lat = _test.loc[:,3]\n",
    "        \n",
    "        y_test_long = _test.loc[:,4]\n",
    "        \n",
    "        X_wide_test = X_wide_scaler.transform(_test.loc[:,6:])\n",
    "\n",
    "        final_test_list = []\n",
    "        for ahead_time in ahead_times:\n",
    "            year_test_list = []\n",
    "            for pressure in pressures:\n",
    "                scaler_name = reanalysis_type +str(pressure) + str(ahead_time)\n",
    "                X_deep = reanalysis_test_dict[scaler_name][reanalysis_test_dict[scaler_name][0].isin(_test[0].unique())].loc[:,5:]\n",
    "                X_deep = X_deep_scaler_dict[scaler_name].transform(X_deep)\n",
    "                X_deep_final = X_deep.reshape(-1, 1, 1, 31, 31)\n",
    "                year_test_list.append(X_deep_final)\n",
    "            X_deep_temp = np.concatenate(year_test_list, axis=2)\n",
    "            final_test_list.append(X_deep_temp)\n",
    "        X_deep_test = np.concatenate(final_test_list, axis=1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            X_wide_test = Variable(torch.from_numpy(X_wide_test).float().cuda())\n",
    "            X_deep_test = Variable(torch.from_numpy(X_deep_test).float().cuda())\n",
    "\n",
    "        pred = net(X_wide_test, X_deep_test)\n",
    "\n",
    "        pred = y_scaler.inverse_transform(pred.cpu().detach().numpy())\n",
    "\n",
    "        pred_lat = pred[:,0]\n",
    "        pred_long = pred[:,1]\n",
    "        true_lat = y_test_lat\n",
    "        true_long = y_test_long\n",
    "\n",
    "        diff_lat = np.abs(pred_lat - true_lat)\n",
    "        diff_long = np.abs(pred_long - true_long)\n",
    "\n",
    "        print('avg lat:', sum(diff_lat)/len(diff_lat))\n",
    "        print('avg long:', sum(diff_long)/len(diff_long))\n",
    "\n",
    "        sum_error = []\n",
    "        for i in range(0, len(pred_lat)):\n",
    "            sum_error.append(great_circle((pred_lat[i], pred_long[i]), (true_lat[i], true_long[i])).kilometers)\n",
    "\n",
    "        print('avg distance error:', sum(sum_error)/len(sum_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
